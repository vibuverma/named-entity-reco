{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KahQ3WXp9Pp9",
        "outputId": "4cae568f-38ed-466b-a6d2-d3c90fde3add"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jan 24 05:54:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpe7bly_8T1D"
      },
      "source": [
        "# Importing Essential Libraries\r\n",
        "import pandas as pd \r\n",
        "import numpy as np \r\n",
        "from itertools import chain\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.optimizers import Optimizer\r\n",
        "\r\n",
        "import tensorflow \r\n",
        "from tensorflow.keras import Sequential, Model, Input\r\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from numpy.random import seed\r\n",
        "seed(1)\r\n",
        "tensorflow.random.set_seed(2)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tNx74lZK8588",
        "outputId": "efb06a53-870b-4f3b-8589-37cec86f03a1"
      },
      "source": [
        "data= pd.read_csv('/content/drive/MyDrive/Named Entity Recognition/ner_dataset.csv', encoding='unicode_escape')\r\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAuMiP3B8_BZ"
      },
      "source": [
        "# Extracting the mappings that are required to train the neural network\r\n",
        "def get_dict_map(data, token_or_tag):\r\n",
        "    tok2idx= {}\r\n",
        "    idx2tok= {}\r\n",
        "    \r\n",
        "    if token_or_tag == 'token':\r\n",
        "        vocab= list(set(data['Word'].to_list()))\r\n",
        "    else:\r\n",
        "        vocab= list(set(data['Tag'].to_list()))\r\n",
        "    \r\n",
        "    idx2tok= {idx:tok for idx, tok in enumerate(vocab)}\r\n",
        "    tok2idx= {tok:idx for idx, tok in enumerate(vocab)}\r\n",
        "    \r\n",
        "    return tok2idx, idx2tok\r\n",
        "\r\n",
        "token2idx, idx2token= get_dict_map(data, 'token')\r\n",
        "tag2idx, idx2tag= get_dict_map(data, 'tag')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1WCsPDK9Bzg",
        "outputId": "cb4c3d85-d4e0-4fd5-f137-e086e2e4ec11"
      },
      "source": [
        "# Transforming the columns to extract the sequential data\r\n",
        "\r\n",
        "data['Word_idx']= data[\"Word\"].map(token2idx)\r\n",
        "data['Tag_idx']= data['Tag'].map(tag2idx)\r\n",
        "\r\n",
        "data_fillna= data.fillna(method='ffill', axis=0)\r\n",
        "\r\n",
        "# Groupby and collect columns\r\n",
        "data_group= data_fillna.groupby([\"Sentence #\"], as_index=False)['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x:list(x))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRhPzbsp9DlS",
        "outputId": "5d53a4cf-4738-40ba-b4a1-c28667717b45"
      },
      "source": [
        "def get_pad_train_test(data_group, data):\r\n",
        "    # get max token and tag length\r\n",
        "    n_token= len(list(set(data[\"Word\"].to_list())))\r\n",
        "    n_tag= len(list(set(data[\"Tag\"].to_list())))\r\n",
        "    \r\n",
        "    # Pad tokens (X var)\r\n",
        "    tokens= data_group['Word_idx'].to_list()\r\n",
        "    maxlen= max([len(s) for s in tokens])\r\n",
        "    pad_tokens= pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value=n_token-1)\r\n",
        "    \r\n",
        "    # Pad Tags (y var) and convert it to one hot encoding\r\n",
        "    tags= data_group['Tag_idx'].to_list()\r\n",
        "    pad_tags= pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value=tag2idx[\"O\"])\r\n",
        "    n_tags= len(tag2idx)\r\n",
        "    pad_tags= [to_categorical(i, num_classes=n_tags) for i in pad_tags]\r\n",
        "    \r\n",
        "    # Splitting into train, test and validation sets\r\n",
        "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\r\n",
        "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\r\n",
        "    \r\n",
        "    print(\r\n",
        "        'train_tokens length:', len(train_tokens),\r\n",
        "        '\\ntrain_tokens length:', len(train_tokens),\r\n",
        "        '\\ntest_tokens length:', len(test_tokens),\r\n",
        "        '\\ntest_tags:', len(test_tags),\r\n",
        "        '\\nval_tokens:', len(val_tokens),\r\n",
        "        '\\nval_tags:', len(val_tags),\r\n",
        "    )\r\n",
        "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags\r\n",
        "\r\n",
        "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test(data_group, data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_tokens length: 32372 \n",
            "train_tokens length: 32372 \n",
            "test_tokens length: 4796 \n",
            "test_tags: 4796 \n",
            "val_tokens: 10791 \n",
            "val_tags: 10791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYX35S7d9HUK"
      },
      "source": [
        "# The layer below will take the dimensions from the LSTM layer and will give the maximum length and maximum tags as output\r\n",
        "input_dim= len(list(set(data['Word'].to_list())))+1\r\n",
        "output_dim= 64\r\n",
        "input_length= max([len(s) for s in data_group['Word_idx'].to_list()])\r\n",
        "n_tags= len(tag2idx)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RXi9w5A9JZR"
      },
      "source": [
        "# Creating a function taht will give summary of each layer\r\n",
        "\r\n",
        "def get_bilstm_lstm_model():\r\n",
        "    model = Sequential()\r\n",
        "\r\n",
        "    # Add Embedding layer\r\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\r\n",
        "\r\n",
        "    # Add bidirectional LSTM\r\n",
        "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\r\n",
        "\r\n",
        "    # Add LSTM\r\n",
        "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\r\n",
        "\r\n",
        "    # Add timeDistributed Layer\r\n",
        "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\r\n",
        "\r\n",
        "    #Optimiser \r\n",
        "    # adam = Optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\r\n",
        "\r\n",
        "    # Compile model\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghW0M2Gi9LCo"
      },
      "source": [
        "# Function to train the model\r\n",
        "\r\n",
        "def train_model(X, y, model):\r\n",
        "    loss = list()\r\n",
        "    for i in range(25):\r\n",
        "        # fit model for one epoch on this sequence\r\n",
        "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\r\n",
        "        loss.append(hist.history['loss'][0])\r\n",
        "    return loss"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7hlUgWE9M4Y",
        "outputId": "7c07370f-910f-468f-ff3b-91a410dd474a"
      },
      "source": [
        "# Main driver function\r\n",
        "results = pd.DataFrame()\r\n",
        "model_bilstm_lstm = get_bilstm_lstm_model()\r\n",
        "plot_model(model_bilstm_lstm)\r\n",
        "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 104, 64)           2251456   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 104, 128)          66048     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 104, 64)           49408     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 104, 17)           1105      \n",
            "=================================================================\n",
            "Total params: 2,368,017\n",
            "Trainable params: 2,368,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "26/26 [==============================] - 38s 1s/step - loss: 1.1502 - accuracy: 0.8272 - val_loss: 0.2580 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2575 - accuracy: 0.9677 - val_loss: 0.2166 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2234 - accuracy: 0.9677 - val_loss: 0.1987 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2041 - accuracy: 0.9677 - val_loss: 0.1821 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2057 - accuracy: 0.9677 - val_loss: 0.2028 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1876 - accuracy: 0.9677 - val_loss: 0.1734 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1772 - accuracy: 0.9677 - val_loss: 0.1697 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.1670 - accuracy: 0.9677 - val_loss: 0.1628 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1588 - accuracy: 0.9678 - val_loss: 0.1609 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1527 - accuracy: 0.9678 - val_loss: 0.1547 - val_accuracy: 0.9682\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1559 - accuracy: 0.9678 - val_loss: 0.1533 - val_accuracy: 0.9682\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.1379 - accuracy: 0.9679 - val_loss: 0.1245 - val_accuracy: 0.9682\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1243 - accuracy: 0.9679 - val_loss: 0.1611 - val_accuracy: 0.9682\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1356 - accuracy: 0.9679 - val_loss: 0.1300 - val_accuracy: 0.9683\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1160 - accuracy: 0.9680 - val_loss: 0.1227 - val_accuracy: 0.9682\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1056 - accuracy: 0.9681 - val_loss: 0.1324 - val_accuracy: 0.9686\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1190 - accuracy: 0.9681 - val_loss: 0.1243 - val_accuracy: 0.9684\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1012 - accuracy: 0.9683 - val_loss: 0.1097 - val_accuracy: 0.9686\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.0951 - accuracy: 0.9685 - val_loss: 0.1108 - val_accuracy: 0.9686\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.0916 - accuracy: 0.9686 - val_loss: 0.1070 - val_accuracy: 0.9690\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.0877 - accuracy: 0.9690 - val_loss: 0.1049 - val_accuracy: 0.9693\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.0852 - accuracy: 0.9694 - val_loss: 0.1042 - val_accuracy: 0.9699\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.0819 - accuracy: 0.9701 - val_loss: 0.1045 - val_accuracy: 0.9705\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.0799 - accuracy: 0.9707 - val_loss: 0.1029 - val_accuracy: 0.9711\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.0819 - accuracy: 0.9710 - val_loss: 0.1053 - val_accuracy: 0.9710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "q2lt3y7u9bRZ",
        "outputId": "13a45c1f-d7b5-4f58-c2b0-55f14e96ae34"
      },
      "source": [
        "import spacy\r\n",
        "import en_core_web_sm\r\n",
        "from spacy import displacy \r\n",
        "nlp= spacy.load('en_core_web_sm')\r\n",
        "text= nlp('Hi my name is Vaibhav Verma. \\n I am a Junior Data Scientist. \\n I work as an intern at Ineuron. ')\r\n",
        "displacy.render(text, style='ent', jupyter=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi my name is \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Vaibhav Verma\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ". </br> I am a \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Junior Data Scientist\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ". </br> I work as an intern at \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ineuron\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ". </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sshEc1lJAszF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}